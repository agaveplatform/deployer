[all:vars]

# General settings to apply to all playbooks. This simply maps a common ssh key and disable host checking. This should
# be disabled in prod, however, when overriding dns from a deployment host, this is handy as it prevents the prompt

# the name of your tenant.
tenant_id=sandbox

# The name of the core service config file to read in.
core_config_file=sandbox

# Set an ip address for the tenant if dns needs to be overridden
#newman_agave_tenant_base_ip=54.183.100.77


[docker_hosts:vars]
# General settings to apply to all hosts. This simply maps a common ssh key and disable host checking. This should
# be disabled in prod, however, when overriding dns from a deployment host, this is handy as it prevents the prompt
ansible_ssh_common_args=-o StrictHostKeyChecking=no -o UserKnownHostsFile=/dev/null

# The common ssh key to use to connect to remote hosts. Can override on each host definition inline
ansible_ssh_private_key_file=~/.ssh/dooley-ec2.pem

# update this if the privileged user account on your agave hosts is different. Usually this will be "root" or "centos"
# depending on your VM image. This will only be used to connect to the host and su to the "apim" account that the
# deployer will create when it configures the hosts.
ansible_ssh_user=centos

# the name of your tenant.
#tenant_id=sandbox

[docker_hosts:children]

auth
core
db
postman
web


[db]
# This group will host the persistence services and should have at least 2 cores, 8GB memory, and 80GB disk.
# Seriously consider clustering the databases and moving them offsite using a multihost deployment.

ec2.db  ansible_ssh_host=54.176.209.154

[db:children]

[auth]

[apim]

[balancer]




[proxy]
# This group will host the science apis and should have at least 2 cores, 8GB memory, and 80GB disk
# This is sufficient for fairly heavy traffic, though you should scale it up to a HA setting if you expect
# high degrees of concurrency in requests and long-lived file uploads/downloads.

ec2.auth  ansible_ssh_host=54.183.100.77


[core]
# This group will host the science apis and should have at least 4 cores, 16GB memory, and 80GB disk
# Seriously consider splitting the worker and core services for any significant traffic or data movement.

ec2.core  ansible_ssh_host=52.8.239.251



[mysql]
# MySQL server host group

[nosql:children]

mongo_mongos
mongo_configs
mongo_shards


[mongo_mongos]
[mongo_configs]
[mongo_shards]

[queue]
# Message queue host group. Beanstalkd, RabbitMQ, etc go here

[cache:children]
# Cache host group. Redis, Memcached go here
redis

[redis]
# RedisDB hosts



[postman]
# Postman test hosts go here.

localhost ansible_connection=local